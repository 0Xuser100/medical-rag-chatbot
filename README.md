# ğŸ¥ Medical RAG Chatbot - Version 1.0

An intelligent medical question-answering chatbot built with **OpenAI GPT**, **LangChain**, and **FAISS** vector search. Get accurate, contextual answers to medical questions based on medical literature with advanced conversational memory.

## âœ¨ Features

- ğŸ¤– **OpenAI GPT Integration** - Powered by GPT-4o-mini for accurate responses
- ğŸ§  **Advanced Memory System** - Remembers conversation context with smart memory management
- ğŸ“š **Medical Knowledge Base** - FAISS vector search through medical documents
- ğŸ’¬ **Modern Chat Interface** - Beautiful, responsive web UI with real-time interactions
- ğŸ“± **Mobile Responsive** - Works seamlessly on all devices
- ğŸ’¾ **Export Conversations** - Download chat history as text files
- ğŸ”„ **Smart Memory Types** - Window memory for short chats, summary memory for long conversations
- ğŸ¯ **Context Awareness** - AI references previous questions and builds on earlier answers

## ğŸš€ Quick Start

### Prerequisites

- Python 3.12
- **Conda** package manager
- OpenAI API key (get from [OpenAI Platform](https://platform.openai.com/))

### 1. Environment Setup with Conda

```bash
# Clone the repository
git clone https://github.com/0Xuser100/medical-rag-chatbot.git
cd MedicalRag

# Create conda environment with Python 3.12
conda create -n medical-rag python=3.12 -y
conda activate medical-rag

# Navigate to app directory and install dependencies
cd app
pip install -r requirements.txt
```

### 2. Configuration

```bash
# Copy the example environment file
cp .env.example .env

# Edit .env and add your OpenAI API key
OPENAI_API_KEY="your_openai_api_key_here"
```

### 3. Prepare Medical Knowledge Base

```bash
# Place your medical PDF files in the data/ directory
# Example: data/medical_encyclopedia.pdf

# Create FAISS vector store from PDFs
python components/data_loader.py
```

### 4. Launch the Chatbot

```bash
# Start the Flask application
python application.py
```

ğŸ‰ **Visit `http://localhost:5000` to start chatting with your medical AI assistant!**

## ğŸ§  Advanced Memory System

### How Memory Works

The chatbot features sophisticated conversational memory:

- **ğŸ”„ Context Retention**: Remembers what you've discussed throughout the conversation
- **ğŸ¯ Follow-up Awareness**: Understands references like "What are the symptoms?" after asking about diabetes
- **ğŸ“Š Smart Memory Types**:
  - **Window Memory** (â‰¤10 messages): Keeps recent conversation turns
  - **Summary Memory** (>10 messages): Summarizes old content, maintains recent context
- **ğŸ’­ Memory Indicators**: UI shows conversation length and active memory type

### Example Conversation Flow

```
You: "What is diabetes?"
AI: "Diabetes is a chronic condition where blood sugar levels are too high..."

You: "What are the symptoms?"  â† AI knows you're still asking about diabetes
AI: "The symptoms of diabetes include increased thirst, frequent urination..."

You: "How is it treated?"  â† AI maintains context about diabetes
AI: "Diabetes treatment involves blood sugar monitoring, medication..."
```

## ğŸ“ Project Structure

```
MedicalRag/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ application.py              # ğŸŒ Main Flask web application
â”‚   â”œâ”€â”€ requirements.txt            # ğŸ“¦ Python dependencies
â”‚   â”œâ”€â”€ .env.example               # ğŸ”§ Environment variables template
â”‚   â”‚
â”‚   â”œâ”€â”€ components/                 # ğŸ”§ Core RAG Components
â”‚   â”‚   â”œâ”€â”€ llm.py                 # ğŸ¤– OpenAI GPT integration
â”‚   â”‚   â”œâ”€â”€ embeddings.py          # ğŸ“Š OpenAI embeddings (text-embedding-3-small)
â”‚   â”‚   â”œâ”€â”€ memory.py              # ğŸ§  Advanced conversation memory system
â”‚   â”‚   â”œâ”€â”€ vector_store.py        # ğŸ—„ï¸ FAISS vector database management
â”‚   â”‚   â”œâ”€â”€ retriever.py           # ğŸ” Document retrieval and QA chain
â”‚   â”‚   â”œâ”€â”€ pdf_loader.py          # ğŸ“„ PDF processing utilities
â”‚   â”‚   â””â”€â”€ data_loader.py         # âš¡ FAISS index creation utility
â”‚   â”‚
â”‚   â”œâ”€â”€ config/                     # âš™ï¸ Configuration
â”‚   â”‚   â””â”€â”€ config.py              # ğŸ”§ Application settings
â”‚   â”‚
â”‚   â”œâ”€â”€ common/                     # ğŸ› ï¸ Utilities
â”‚   â”‚   â”œâ”€â”€ logger.py              # ğŸ“ Logging system
â”‚   â”‚   â””â”€â”€ custom_exception.py    # â— Exception handling
â”‚   â”‚
â”‚   â”œâ”€â”€ templates/                  # ğŸ¨ Web Interface
â”‚   â”‚   â””â”€â”€ index.html             # ğŸ’¬ Modern chat UI
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                      # ğŸ“š Medical Documents
â”‚   â”‚   â””â”€â”€ *.pdf                  # Your medical PDF files
â”‚   â”‚
â”‚   â””â”€â”€ vectorstore/               # ğŸ—ƒï¸ Vector Database
â”‚       â””â”€â”€ db_faiss/              # FAISS index files
â”‚           â”œâ”€â”€ index.faiss
â”‚           â””â”€â”€ index.pkl
â””â”€â”€ README.md                      # ğŸ“– This file
```

## âš™ï¸ Configuration

### Model Settings (`config/config.py`)
```python
OPEN_AI_MODEL = "gpt-4o-mini"      # OpenAI model (fast, cost-effective)
CHUNK_SIZE = 500                   # Text chunk size for processing
CHUNK_OVERLAP = 50                 # Overlap between chunks for context
```

### Available OpenAI Models
- `gpt-4o-mini` âœ… (default - fast, economical)
- `gpt-4o` (more capable, higher cost)
- `gpt-4-turbo` (previous generation)

### Memory Configuration
- **Window Memory**: Keeps 3-6 recent message pairs
- **Summary Memory**: Summarizes conversations >10 messages
- **Auto-switching**: System automatically chooses optimal memory type

## ğŸ”§ Usage Examples

### Basic Medical Queries
```
"What is hypertension?"
"Explain the symptoms of pneumonia"
"How is diabetes diagnosed?"
```

### Conversational Follow-ups
```
User: "What is asthma?"
AI: "Asthma is a respiratory condition..."

User: "What triggers it?"  â† AI knows "it" refers to asthma
AI: "Asthma can be triggered by allergens, exercise..."

User: "Any prevention methods?"  â† Continues context
AI: "To prevent asthma attacks, avoid known triggers..."
```

### UI Features
- **ğŸ’¾ Export Chat**: Download conversation as `.txt` file
- **ğŸ—‘ï¸ Clear History**: Reset conversation and memory
- **ğŸ“Š Message Counter**: Track conversation length
- **ğŸ§  Memory Status**: Visual indicator when smart memory is active

## ğŸ“š Managing Medical Knowledge Base

### Adding New Documents

1. **Add PDF files** to the `data/` directory
2. **Recreate vector store**:
   ```bash
   conda activate medical-rag
   python components/data_loader.py
   ```
3. **Restart application** to use updated knowledge base

### Supported Document Types
- âœ… PDF files (medical textbooks, research papers, clinical guidelines)
- âœ… Text-based PDFs (searchable content)
- âŒ Image-only PDFs (not supported)

## ğŸ› ï¸ Development & Troubleshooting

### Development Mode
```bash
conda activate medical-rag
export FLASK_DEBUG=1  # Enable debug mode
python application.py
```

### Common Issues & Solutions

**ğŸ”‘ OpenAI API Error**
```
Error: API connection error
```
**Solution**: 
- Verify `OPENAI_API_KEY` in `.env` file
- Check OpenAI account credits
- Ensure stable internet connection

**ğŸ—„ï¸ Vector Store Not Found**
```
Error: No vector store found
```
**Solution**:
```bash
python components/data_loader.py
```

**ğŸ“„ PDF Processing Error**
```
Error: No documents loaded from PDFs
```
**Solution**:
- Ensure PDF files are in `data/` directory
- Verify PDFs are readable (not corrupted/password-protected)
- Check PDF contains extractable text

**ğŸ§  Memory Issues**
```
Error: Failed to create conversational memory
```
**Solution**:
- Verify all dependencies installed: `pip install -r requirements.txt`
- Check OpenAI API key validity
- Restart application

### Dependencies (`requirements.txt`)
```txt
langchain==0.3.27
langchain_community==0.3.29
langchain-openai==0.3.32
faiss-cpu==1.12.0
pypdf==6.0.0
flask==3.1.2
python-dotenv==1.1.1
```

## ğŸš€ Deployment

### Production Environment Variables
```bash
OPENAI_API_KEY=your_production_api_key
FLASK_ENV=production
```

### Docker Deployment
```dockerfile
FROM python:3.12-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies
COPY app/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY app/ .

# Expose port
EXPOSE 5000

# Run application
CMD ["python", "application.py"]
```

### Build and Run Docker Container
```bash
# Build image
docker build -t medical-rag-chatbot .

# Run container
docker run -p 5000:5000 -e OPENAI_API_KEY=your_key medical-rag-chatbot
```

## ğŸ”¬ Technical Architecture

### RAG Pipeline Flow
1. **ğŸ“„ Document Processing**: PDFs â†’ Text Chunks
2. **ğŸ”¢ Embeddings**: Text â†’ OpenAI Embeddings (1536 dimensions)
3. **ğŸ—„ï¸ Vector Storage**: Embeddings â†’ FAISS Index
4. **ğŸ” Query Processing**: Question â†’ Similarity Search â†’ Context Retrieval
5. **ğŸ¤– Response Generation**: Context + Memory + Question â†’ GPT Response
6. **ğŸ§  Memory Update**: Store conversation turn for future context

### Memory Architecture
- **Session Storage**: Flask sessions store message history
- **Dynamic Memory**: Creates fresh memory context per request
- **Context Population**: Rebuilds conversational context from session
- **Smart Switching**: Chooses memory type based on conversation length

## ğŸ“Š Performance & Costs

### OpenAI API Costs (Approximate)
- **GPT-4o-mini**: ~$0.0001 per 1K input tokens
- **Embeddings**: ~$0.00002 per 1K tokens
- **Average conversation**: $0.01-0.05 depending on length

### Performance Metrics
- **Response time**: 2-5 seconds (depending on context length)
- **Memory efficiency**: Automatic summarization for long conversations
- **Vector search**: Sub-second similarity search with FAISS

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes and test thoroughly
4. Commit: `git commit -m 'Add amazing feature'`
5. Push: `git push origin feature/amazing-feature`
6. Open a Pull Request

### Development Guidelines
- Follow existing code structure and patterns
- Add comprehensive error handling
- Update README.md for new features
- Test with various medical documents
- Ensure memory system compatibility

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **[OpenAI](https://openai.com/)** for GPT models and embeddings API
- **[LangChain](https://langchain.com/)** for RAG framework and memory systems
- **[FAISS](https://github.com/facebookresearch/faiss)** for efficient vector similarity search
- **[Flask](https://flask.palletsprojects.com/)** for web application framework

## ğŸ“ Support

For support and questions:
- ğŸ› **Bug Reports**: Create an issue on GitHub
- ğŸ’¡ **Feature Requests**: Open a discussion on GitHub
- ğŸ“š **Documentation**: Check this README and code comments
- ğŸ”§ **Configuration Help**: Review the troubleshooting section

---

## âš ï¸ Medical Disclaimer

**Important**: This chatbot is designed for **informational and educational purposes only**. It should **never be used as a substitute** for professional medical advice, diagnosis, or treatment. 

- Always consult qualified healthcare providers for medical decisions
- In case of medical emergencies, contact emergency services immediately
- The AI responses are based on training data and may contain errors
- Medical knowledge evolves rapidly; always verify information with current sources

---

**Version 1.0** | Built with â¤ï¸ for medical education and research | Powered by OpenAI & Python 3.12